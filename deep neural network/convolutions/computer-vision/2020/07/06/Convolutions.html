<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Convolutions in Deep Neural Network | Entiretydotai</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Convolutions in Deep Neural Network" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An in depth introduction to different concepts in Convolution" />
<meta property="og:description" content="An in depth introduction to different concepts in Convolution" />
<link rel="canonical" href="https://entiretydotai.github.io/blogs/deep%20neural%20network/convolutions/computer-vision/2020/07/06/Convolutions.html" />
<meta property="og:url" content="https://entiretydotai.github.io/blogs/deep%20neural%20network/convolutions/computer-vision/2020/07/06/Convolutions.html" />
<meta property="og:site_name" content="Entiretydotai" />
<meta property="og:image" content="https://entiretydotai.github.io/blogs/images/convolutions.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-06T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://entiretydotai.github.io/blogs/deep%20neural%20network/convolutions/computer-vision/2020/07/06/Convolutions.html"},"description":"An in depth introduction to different concepts in Convolution","@type":"BlogPosting","url":"https://entiretydotai.github.io/blogs/deep%20neural%20network/convolutions/computer-vision/2020/07/06/Convolutions.html","headline":"Convolutions in Deep Neural Network","dateModified":"2020-07-06T00:00:00-05:00","datePublished":"2020-07-06T00:00:00-05:00","image":"https://entiretydotai.github.io/blogs/images/convolutions.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blogs/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://entiretydotai.github.io/blogs/feed.xml" title="Entiretydotai" /><link rel="shortcut icon" type="image/x-icon" href="/blogs/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Convolutions in Deep Neural Network | Entiretydotai</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Convolutions in Deep Neural Network" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An in depth introduction to different concepts in Convolution" />
<meta property="og:description" content="An in depth introduction to different concepts in Convolution" />
<link rel="canonical" href="https://entiretydotai.github.io/blogs/deep%20neural%20network/convolutions/computer-vision/2020/07/06/Convolutions.html" />
<meta property="og:url" content="https://entiretydotai.github.io/blogs/deep%20neural%20network/convolutions/computer-vision/2020/07/06/Convolutions.html" />
<meta property="og:site_name" content="Entiretydotai" />
<meta property="og:image" content="https://entiretydotai.github.io/blogs/images/convolutions.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-06T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://entiretydotai.github.io/blogs/deep%20neural%20network/convolutions/computer-vision/2020/07/06/Convolutions.html"},"description":"An in depth introduction to different concepts in Convolution","@type":"BlogPosting","url":"https://entiretydotai.github.io/blogs/deep%20neural%20network/convolutions/computer-vision/2020/07/06/Convolutions.html","headline":"Convolutions in Deep Neural Network","dateModified":"2020-07-06T00:00:00-05:00","datePublished":"2020-07-06T00:00:00-05:00","image":"https://entiretydotai.github.io/blogs/images/convolutions.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://entiretydotai.github.io/blogs/feed.xml" title="Entiretydotai" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blogs/">Entiretydotai</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blogs/about/">About us</a><a class="page-link" href="/blogs/search/">Search</a><a class="page-link" href="/blogs/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Convolutions in Deep Neural Network</h1><p class="page-description">An in depth introduction to different concepts in Convolution</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-07-06T00:00:00-05:00" itemprop="datePublished">
        Jul 6, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blogs/categories/#deep neural network">deep neural network</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blogs/categories/#convolutions">convolutions</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blogs/categories/#computer-vision">computer-vision</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/entiretydotai/blogs/tree/master/_notebooks/2020-07-06-Convolutions.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blogs/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/entiretydotai/blogs/master?filepath=_notebooks%2F2020-07-06-Convolutions.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blogs/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/entiretydotai/blogs/blob/master/_notebooks/2020-07-06-Convolutions.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blogs/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Why-CNN-and-not-Regular-Neural-Nets">Why CNN and not Regular Neural Nets </a></li>
<li class="toc-entry toc-h1"><a href="#Convolution">Convolution </a></li>
<li class="toc-entry toc-h1"><a href="#Convolution-over-Volume">Convolution over Volume </a></li>
<li class="toc-entry toc-h1"><a href="#Convolution-Operation-with-Multiple-Filters">Convolution Operation with Multiple Filters </a></li>
<li class="toc-entry toc-h1"><a href="#General-Representation">General Representation </a></li>
<li class="toc-entry toc-h1"><a href="#One-Convolution-layer">One Convolution layer </a></li>
<li class="toc-entry toc-h1"><a href="#Strides">Strides </a></li>
<li class="toc-entry toc-h1"><a href="#Padding">Padding </a></li>
<li class="toc-entry toc-h1"><a href="#Pooling">Pooling </a></li>
<li class="toc-entry toc-h1"><a href="#General-Representation-Updated">General Representation-Updated </a></li>
<li class="toc-entry toc-h1"><a href="#Examples">Examples </a></li>
<li class="toc-entry toc-h1"><a href="#1-x-1-Convolution">1 x 1 Convolution </a></li>
<li class="toc-entry toc-h1"><a href="#"></a></li>
<li class="toc-entry toc-h1"><a href="#Receptive-Field">Receptive Field </a></li>
<li class="toc-entry toc-h1"><a href="#Things-to-remember">Things to remember </a></li>
<li class="toc-entry toc-h1"><a href="#References">References </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-06-Convolutions.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Why-CNN-and-not-Regular-Neural-Nets">
<a class="anchor" href="#Why-CNN-and-not-Regular-Neural-Nets" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why CNN and not Regular Neural Nets<a class="anchor-link" href="#Why-CNN-and-not-Regular-Neural-Nets"> </a>
</h1>
<p><strong>1. Regular Neural Nets don’t scale well to full images</strong></p>
<p>In MNIST dataset,images are only of size 28x28x1 (28 wide, 28 high, 1 color channels), so a single fully-connected neuron in a first hidden layer of a regular Neural Network would have 28x28x1 = 786 weights. This amount still seems manageable,</p>
<p><strong>But what if we move to larger images.</strong></p>
<p>For example, an image of more respectable size, e.g. 200x200x3, would lead to neurons that have 200x200x3 = 120,000 weights. Moreover, we would almost certainly want to have several such neurons, so the parameters would add up quickly! Clearly, this full connectivity is wasteful and the huge number of parameters would quickly lead to overfitting.</p>
<p><strong>2.Parameter Sharing</strong>
<br>
A feature detector that is useful in one part of the image is probably useful in another part of the image.Thus CNN are good in capturing translation invariance.</p>
<p><strong>Sparsity of connections</strong>
In each layer,each output value depends only on a small number of inputs.This makes CNN networks easy to train on smaller training datasets and is less prone to overfitting.</p>
<p><strong>2.3D volumes of neurons.</strong>
Convolutional Neural Networks take advantage of the fact that the input consists of images and they constrain the architecture in a more sensible way. In particular, unlike a regular Neural Network, the layers of a ConvNet have neurons arranged in 3 dimensions: width, height, depth.</p>
<p><img src="/blogs/images/copied_from_nb/images/ffnvscnn.PNG" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Convolution">
<a class="anchor" href="#Convolution" aria-hidden="true"><span class="octicon octicon-link"></span></a>Convolution<a class="anchor-link" href="#Convolution"> </a>
</h1>
<p>In purely mathematical terms, convolution is a function derived from two given functions by integration which expresses how the shape of one is modified by the other.</p>
<p>However we are interested in understanding the actual convolution operation in the context of neural networks.</p>
<p><strong>An intuitive understanding of Convolution</strong>
<br>
Convolution is an operation done  to extract features from the images as these features will be used by the network to learn about a particular image.In the case of a dog image,the feature could be the shape of a nose or the shape of an eye which will help the network later to identify an image as a dog.</p>
<p>Convolution operation is performed with the help of the following three elements:</p>
<p><strong>1.Input Image-</strong> The image to convolve on</p>
<p><strong>2.Feature Detector/Kernel/Filter-</strong> They are the bunch of numbers in a matrix form intended to extract features from an image.They can be 1dimensional ,2-dimensional or 3-dimensional</p>
<p><strong>3.Feature Map/Activation Map-</strong> The resultant of the convolution operation performed between image and feature detector gives a Feature Map.</p>
<p><img src="/blogs/images/copied_from_nb/images/convolution.PNG" alt=""></p>
<p><img src="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/03/convolution.png" alt=""></p>
<p><img src="/blogs/images/copied_from_nb/images/feature1.PNG" alt="">
<img src="/blogs/images/copied_from_nb/images/feature2.PNG" alt="">
<img src="/blogs/images/copied_from_nb/images/feature3.PNG" alt=""></p>
<p><strong>Convolution Operation</strong></p>
<p><img src="https://cdn-images-1.medium.com/max/1200/1*VVvdh-BUKFh2pwDD0kPeRA@2x.gif" alt=""></p>
<p><strong>Another way to look at it</strong></p>
<p><img src="/blogs/images/copied_from_nb/images/conv3d1.png" alt=""></p>
<p>Let say we have an input of $6 x 6$  and a filter size $3 x 3$</p>
<p><strong>Feature map is of size   $4 x 4$</strong>
<img src="/blogs/images/copied_from_nb/images/conv1.PNG" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Convolution-over-Volume">
<a class="anchor" href="#Convolution-over-Volume" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Convolution over Volume</strong><a class="anchor-link" href="#Convolution-over-Volume"> </a>
</h1>
<p><strong>What if our input image has more than one channel?</strong></p>
<p>Let say we have an input of $6 x 6 x 3$  and a filter size $3 x 3 x 3$</p>
<p><strong>Feature map is of size   $4 x 4$</strong></p>
<p><img src="/blogs/images/copied_from_nb/images/conv3d.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Convolution-Operation-with-Multiple-Filters">
<a class="anchor" href="#Convolution-Operation-with-Multiple-Filters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Convolution Operation with Multiple Filters<a class="anchor-link" href="#Convolution-Operation-with-Multiple-Filters"> </a>
</h1>
<p>Let say we have an input of $6 x 6 x 3$  and we use two filters size $3 x 3$</p>
<p><strong>Feature map is of size   $4 x 4 x 2$</strong></p>
<p><img src="/blogs/images/copied_from_nb/images/conv2.PNG" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="General-Representation">
<a class="anchor" href="#General-Representation" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>General Representation</strong><a class="anchor-link" href="#General-Representation"> </a>
</h1>
<p><br>

$$Input Image [n(h)*n(w)*n(c)]-Filter-[f(h)*f(w)*n(c)],n(c')--Feature Map--[(n-f+1)*(n-f+1)*n(c')]$$
</p>
<p><strong>$n(h)$</strong>-height of the image</p>
<p><strong>$n(w)$</strong>-width of the image</p>
<p><strong>$n(c)$</strong>-number of channel in an image</p>
<p><strong>$f(h)$</strong>-height of the filter</p>
<p><strong>$f(w)$</strong>-width of the filter</p>
<p><strong>$f(c')$</strong>-no of the filter</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="One-Convolution-layer">
<a class="anchor" href="#One-Convolution-layer" aria-hidden="true"><span class="octicon octicon-link"></span></a>One Convolution layer<a class="anchor-link" href="#One-Convolution-layer"> </a>
</h1>
<p><img src="/blogs/images/copied_from_nb/images/convlayer.PNG" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Strides">
<a class="anchor" href="#Strides" aria-hidden="true"><span class="octicon octicon-link"></span></a>Strides<a class="anchor-link" href="#Strides"> </a>
</h1>
<p><img src="/blogs/images/copied_from_nb/images/stride.PNG" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Padding">
<a class="anchor" href="#Padding" aria-hidden="true"><span class="octicon octicon-link"></span></a>Padding<a class="anchor-link" href="#Padding"> </a>
</h1>
<p><img src="/blogs/images/copied_from_nb/images/padding.PNG" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Pooling">
<a class="anchor" href="#Pooling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pooling<a class="anchor-link" href="#Pooling"> </a>
</h1>
<p><img src="/blogs/images/copied_from_nb/images/pooling.PNG" alt=""></p>
<p><strong>Why we do Pooling?</strong></p>
<p>The idea of max pooling is:</p>
<ol>
<li>to reduce the size of representation in such a way that we carry along those features which speaks louder in the image </li>
<li>to lower the number of parameters to be computed,speeding the computation </li>
<li>to make some of the features that detects significant things a bit more robust.</li>
</ol>
<p><strong>Analogy that I like to draw</strong>
<img src="https://qph.fs.quoracdn.net/main-qimg-0eb448b5633a1ff511ac2956f032f816-c" alt=""></p>
<p>A good analogy to draw here would be to look into the history of shapes of pyramid.</p>
<p>The Greek pyramid is the one without max pooling whereas the Mesopotamian pyramid is with max pooling involved where we are loosing more information but making our network simpler than the other one.</p>
<p><strong>But don't we end up loosing information by max pooling?</strong></p>
<p>Yes we do but the question we need to ask is how much information we can afford to loose without impacting much on the model prediction.</p>
<p>Perhaps the criteria to choose how often(after how many convolutions) and at what part of the network (at the beginning or at the mid or at the end of the network) to use max pooling depends completely on what this network is being used for.</p>
<p>For eg:</p>
<ol>
<li>Cats vs Dogs</li>
<li>Identify the age of a person</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="General-Representation-Updated">
<a class="anchor" href="#General-Representation-Updated" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>General Representation-Updated</strong><a class="anchor-link" href="#General-Representation-Updated"> </a>
</h1>
<p><br></p>
<p><strong>Including Padding and Stride</strong></p>
<p>
$$Input Image [n(h)*n(w)*n(c)]-Filter-[f(h)*f(w)*n(c)],n(c')--Feature Map--[((n-f+2p)/s+1)*((n-f+2p)/s+1)*n(c')]$$
</p>
<p><strong>$n(h)$</strong>-height of the image</p>
<p><strong>$n(w)$</strong>-width of the image</p>
<p><strong>$n(c)$</strong>-number of channel in an image</p>
<p><strong>$f(h)$</strong>-height of the filter</p>
<p><strong>$f(w)$</strong>-width of the filter</p>
<p><strong>$f(c')$</strong>-no of the filter</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blogs/images/copied_from_nb/images/network.PNG" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Examples">
<a class="anchor" href="#Examples" aria-hidden="true"><span class="octicon octicon-link"></span></a>Examples<a class="anchor-link" href="#Examples"> </a>
</h1>
<p><strong>Input volume:</strong> 32x32x3
<br>
10 5x5 filters with stride 1, pad 2
<br>
Output volume size: ?</p>
<p>32x32x10</p>
<p><strong>Input volume:</strong> 32x32x3
<br>
10 5x5 filters with stride 1, pad 2
<br></p>
<p>Number of parameters in this layer?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="1-x-1-Convolution">
<a class="anchor" href="#1-x-1-Convolution" aria-hidden="true"><span class="octicon octicon-link"></span></a>1 x 1 Convolution<a class="anchor-link" href="#1-x-1-Convolution"> </a>
</h1>
<p>At first,the idea of using 1x1 filter seems to not make sense as  1x1 convolution is just multiplying  by numbers.We will not be learning any feature here.</p>
<p>But wait... What if we have a layer with dimension 32x32x196,here 196 is the number of channels and we want to do convolution</p>
<p>So 1x1x192 convolution will do the work of dimensionality reduction by looking at each of the 196 different positions  and it will do the element wise product and give out one number.Using multiple such filters say 32 will give 32 variations of this number.</p>
<p><img src="/blogs/images/copied_from_nb/images/1x1.gif" alt="">
<strong>Why do we use 1x1 filter</strong></p>
<ol>
<li>
<p>1x 1 filter can help in shrinking the number of channels or increasing the number of channels without changing the height and width of the layer.</p>
</li>
<li>
<p>It adds nonlinearity in the network which is useful in some of the architectures like Inception network.</p>
</li>
</ol>
<h1>
<a class="anchor" href="#" aria-hidden="true"><span class="octicon octicon-link"></span></a><img src="https://cdn-images-1.medium.com/max/1600/1*KdLQiGlPWSxYJ-dvYM3tyQ.png" alt="">
</h1>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Receptive-Field">
<a class="anchor" href="#Receptive-Field" aria-hidden="true"><span class="octicon octicon-link"></span></a>Receptive Field<a class="anchor-link" href="#Receptive-Field"> </a>
</h1>
<p>The receptive field is defined as the region in the input space that a particular CNN’s feature is looking at (i.e. be affected by). A receptive field of a feature can be described by its center location and its size.</p>
<p><img src="/blogs/images/copied_from_nb/images/receptive_field.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Things-to-remember">
<a class="anchor" href="#Things-to-remember" aria-hidden="true"><span class="octicon octicon-link"></span></a>Things to remember<a class="anchor-link" href="#Things-to-remember"> </a>
</h1>
<ol>
<li>
<p><strong>Filter</strong> will always have the same number of channel as the image.</p>
</li>
<li>
<p><strong>Convolving</strong> gives a <strong>2 D feature map</strong> although our image and kernel used are of 3 dimensional</p>
</li>
<li>
<p><strong>Padding</strong> -Preserves the feature size</p>
</li>
<li>
<p><strong>Pooling Operation</strong>- Reduces the Input feature size by half</p>
</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="References">
<a class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a>References<a class="anchor-link" href="#References"> </a>
</h1>
<p><a href="https://indoml.com/2018/03/07/student-notes-convolutional-neural-networks-cnn-introduction/">Convolution</a>
<br>
<a href="https://wiseodd.github.io/techblog/2016/07/18/convnet-maxpool-layer/">Max Pool</a>
<br>
<a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture05.pdf">Standford Slides</a>
<br>
<a href="http://cs231n.github.io/convolutional-networks/">Standford Blog</a>
<br>
<a href="https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050">An intuitive guide to Convolutional Neural Networks</a>
<br>
<a href="https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2">Convolutional Neural Networks</a>
<br>
<a href="https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148">Understanding of Convolutional Neural Network</a>
<br>
<a href="https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807">Receptive Feild Calculation</a>
<br>
<a href="http://timdettmers.com/2015/03/26/convolution-deep-learning/">Understanding Convolution in Deep Learning</a>
<br>
<a href="http://setosa.io/ev/image-kernels/">Visualize Image Kernel</a>
<br>
<a href="https://arxiv.org/abs/1311.2901">Visualizing and Understanding Convolution Networks</a></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="entiretydotai/blogs"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blogs/deep%20neural%20network/convolutions/computer-vision/2020/07/06/Convolutions.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blogs/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blogs/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blogs/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>ML/DL Meetup Community.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/entiretydotai" title="entiretydotai"><svg class="svg-icon grey"><use xlink:href="/blogs/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/entiretydotai" title="entiretydotai"><svg class="svg-icon grey"><use xlink:href="/blogs/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
